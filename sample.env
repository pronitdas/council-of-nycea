# Development Environment Variables
NODE_ENV=development

# LLM Service Configuration
OPENAI_API_KEY=your-openai-key-here
ANTHROPIC_API_KEY=your-anthropic-key-here
OLLAMA_URL=http://localhost:11434
LLM_STUDIO_URL=http://localhost:1234
LLM_PROVIDER_ENCRYPTION_KEY=dev-encryption-key-change-in-production

# TEI (Text Embeddings Inference) Configuration
TEI_EMBEDDING_URL=http://localhost:8080
TEI_RERANKER_URL=http://localhost:8081
TEI_EMBEDDING_CPU_URL=http://localhost:8082
TEI_EMBEDDING_MODEL=BAAI/bge-large-en-v1.5
TEI_RERANKER_MODEL=BAAI/bge-reranker-base
TEI_EMBEDDING_CPU_MODEL=sentence-transformers/all-mpnet-base-v2
TEI_REQUEST_TIMEOUT=30000
TEI_RETRY_ATTEMPTS=3

# Hugging Face Configuration (for private models)
# HF_TOKEN=your_huggingface_token_here

# Docker Compose Profiles
# COMPOSE_PROFILES=gpu           # Use for GPU-enabled TEI services
# COMPOSE_PROFILES=cpu-only      # Use for CPU-only TEI services

# Development URLs
VITE_API_URL=http://localhost:8081 